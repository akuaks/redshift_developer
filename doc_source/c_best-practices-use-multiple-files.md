# Split your load data<a name="c_best-practices-use-multiple-files"></a>

When you load compressed data, with the COPY command from multiple files, the data loads in parallel\. This divides the workload among the nodes in your cluster\. When you load all the data from a single large, compressed file, Amazon Redshift is forced to perform a serialized load, which is much slower\. 

In contrast, when you load delimited data from a large, uncompressed file, Amazon Redshift makes use of multiple slices\. These slices work in parallel, automatically\. This provides fast load performance\. Specifically, when Amazon Redshift loads uncompressed, delimited data, data is split into ranges and handled by slices in each node\.

If you intend to load data from a large, compressed file, we recommend that you split your data into smaller files that are about equal size, from 1 MB to 1 GB after compression\. For optimum parallelism, the ideal file size is 1â€“125 MB after compression\. Make the number of files a multiple of the number of slices in your cluster\. For more information about how to split your data into files and examples of using COPY to load data, see [Loading data from Amazon S3](t_Loading-data-from-S3.md)\. 